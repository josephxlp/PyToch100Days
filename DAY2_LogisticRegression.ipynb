{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRAYAVr2dzbTx7zWqjq8d0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/josephxlp/PyTorch100Days/blob/main/DAY2_LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DAY2 : Logistic Regression Classfication"
      ],
      "metadata": {
        "id": "bQZpIuvyczD7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Description:\n",
        "\n",
        " - buidld a binary classifier using logistic regression in PyTorch.\n",
        " - learn to classify points in 2D space using a sigmoid activation and binary cross-entropy loss.\n",
        "\n",
        "\n",
        " Goal: Predict binary class (0/1) via sigmoid(wx+b)"
      ],
      "metadata": {
        "id": "rJu0ZeY-dBRj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1GWg503BcqyI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Example input features and binary labels (0 or 1)\n",
        "X = torch.tensor([[1.0], [2.0], [3.0], [4.0]])  # Feature values\n",
        "y = torch.tensor([[0.0], [0.0], [1.0], [1.0]])  # Labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a logistic regression model (layers: linear-logistc)\n",
        "\n",
        "class LogisticRegression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LogisticRegression, self).__init__()\n",
        "    self.linear = nn.Linear(1, 1)  # 1 input feature, 1 output\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = torch.sigmoid(self.linear(x))\n",
        "    return out\n",
        "\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Binary Cross-Entropy loss for binary classification\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "# training loop\n",
        "\n",
        "for epoch in range(1000):\n",
        "  p = model(X) # forward pass\n",
        "  loss = criterion(p,y) # loss\n",
        "  optimizer.zero_grad() # reset the grad\n",
        "  loss.backward() # backprogration\n",
        "  optimizer.step() # update the weights\n",
        "  if (epoch + 1) % 100 == 0:\n",
        "    print(f'Epoch [{epoch+1}/1000], Loss: {loss.item():.4f}')\n",
        "\n",
        "# print the learned params\n",
        "print('Learned Parameters:')\n",
        "for name, param in model.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    print(f'{name}: {param.data}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEz15wTqdztp",
        "outputId": "a450c7af-f32c-421e-a760-0854f4cb6af1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 0.6649\n",
            "Epoch [200/1000], Loss: 0.6079\n",
            "Epoch [300/1000], Loss: 0.5839\n",
            "Epoch [400/1000], Loss: 0.5621\n",
            "Epoch [500/1000], Loss: 0.5418\n",
            "Epoch [600/1000], Loss: 0.5228\n",
            "Epoch [700/1000], Loss: 0.5051\n",
            "Epoch [800/1000], Loss: 0.4886\n",
            "Epoch [900/1000], Loss: 0.4731\n",
            "Epoch [1000/1000], Loss: 0.4586\n",
            "Learned Parameters:\n",
            "linear.weight: tensor([[0.6567]])\n",
            "linear.bias: tensor([-1.1304])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "params = list(model.parameters())\n",
        "print(f'Learned weight: {params[0].item():.4f}, bias: {params[1].item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPmQhCo6fPwp",
        "outputId": "0eb6e69c-2820-4ee9-c4ff-b37214f45a15"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learned weight: 0.6567, bias: -1.1304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SPMUZQQwfYNp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}